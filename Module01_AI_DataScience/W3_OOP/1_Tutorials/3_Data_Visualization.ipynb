{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis, Preprocessing, and Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This tutorial covers the importance of data analysis, preprocessing, and exploratory data analysis (EDA). It includes various steps for data cleaning, transformation, visualization, and feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Preprocessing\n",
    "Data preprocessing involves cleaning and preparing data for analysis. This includes handling missing values, removing outliers, and transforming data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data_url = 'https://path-to-your-dataset.csv'\n",
    "data = pd.read_csv(data_url)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Values\n",
    "If missing values are found, they can be handled by removing the rows/columns or by replacing them with appropriate values (e.g., mean, median, mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean of the column\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "# Verify that there are no more missing values\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Outliers\n",
    "Outliers can be detected and removed to prevent them from skewing the analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove outliers based on z-score\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def remove_outliers(df, column):\n",
    "    z_scores = zscore(df[column])\n",
    "    abs_z_scores = np.abs(z_scores)\n",
    "    filtered_entries = (abs_z_scores < 3)\n",
    "    return df[filtered_entries]\n",
    "\n",
    "# Example of removing outliers from a numerical column\n",
    "data = remove_outliers(data, 'numerical_column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transformation\n",
    "Ensure all columns have appropriate data types. For instance, convert numerical columns to integers or floats if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a column to integer type\n",
    "data['integer_column'] = data['integer_column'].astype(int)\n",
    "# Convert a column to float type\n",
    "data['float_column'] = data['float_column'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Exploratory Data Analysis (EDA)\n",
    "EDA involves analyzing the main characteristics of the data, often using visual methods. It helps in understanding the data distribution, relationships between variables, and identifying patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Statistics\n",
    "Calculate basic statistical measures such as mean, median, and standard deviation for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of the dataset\n",
    "summary_statistics = data.describe()\n",
    "summary_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization\n",
    "Visualize the distribution of numerical features and the relationships between variables using various plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Histogram\n",
    "Visualize the distribution of a numerical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Histogram of a numerical feature\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['numerical_feature'], kde=True, bins=30)\n",
    "plt.title('Distribution of Numerical Feature')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scatter Plot\n",
    "Visualize the relationship between two numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of two numerical features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='feature1', y='feature2', data=data)\n",
    "plt.title('Relationship between Feature1 and Feature2')\n",
    "plt.xlabel('Feature1')\n",
    "plt.ylabel('Feature2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bar Plot\n",
    "Visualize the count of each category in a categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of a categorical feature\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='categorical_feature', data=data)\n",
    "plt.title('Count of Categories in Categorical Feature')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
    ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pie Chart\n",
    "Visualize the proportion of each category in a categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of a categorical feature\n",
    "category_counts = data['categorical_feature'].value_counts()\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Proportion of Categories in Categorical Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heatmap\n",
    "Visualize the correlation matrix of the features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = data.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix of Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Feature Engineering\n",
    "Feature engineering involves creating new features from existing ones to improve the performance of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new features\n",
    "data['Total Curricular Units Completed'] = data['Curricular units 1st sem (approved)'] + data['Curricular units 2nd sem (approved)']\n",
    "data['Average Grade'] = (data['Curricular units 1st sem (grade)'] + data['Curricular units 2nd sem (grade)']) / 2\n",
    "data['Units Passed Ratio'] = data['Total Curricular Units Completed'] / (data['Curricular units 1st sem (enrolled)'] + data['Curricular units 2nd sem (enrolled)'])\n",
    "\n",
    "# Display the new features\n",
    "data[['Total Curricular Units Completed', 'Average Grade', 'Units Passed Ratio']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Infinite and NaN Values\n",
    "Replace infinite values with the mean and fill NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinite values with NaN\n",
    "data['Units Passed Ratio'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaN values with the mean\n",
    "mean_units_passed_ratio = data['Units Passed Ratio'].mean()\n",
    "data['Units Passed Ratio'].fillna(mean_units_passed_ratio, inplace=True)\n",
    "\n",
    "# Check the updated statistics\n",
    "data[['Total Curricular Units Completed', 'Average Grade', 'Units Passed Ratio']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Advanced Analysis\n",
    "Perform advanced data analysis such as regression, clustering, and hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Analysis\n",
    "Use linear regression to explore the relationship between independent variables and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define features and target\n",
    "X = data[['feature1', 'feature2', 'feature3']]\n",
    "y = data['target']\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print the coefficients\n",
    "print('Coefficients:', model.coef_)\n",
    "print('Intercept:', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering\n",
    "Use clustering algorithms like K-means to identify groups within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Define features for clustering\n",
    "X = data[['feature1', 'feature2']]\n",
    "\n",
    "# Initialize and train the model\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Add cluster labels to the data\n",
    "data['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='feature1', y='feature2', hue='Cluster', data=data, palette='viridis')\n",
    "plt.title('Clusters of Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis Testing\n",
    "Use hypothesis testing to compare groups within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Define two groups\n",
    "group1 = data[data['categorical_feature'] == 'Category1']['numerical_feature']\n",
    "group2 = data[data['categorical_feature'] == 'Category2']['numerical_feature']\n",
    "\n",
    "# Perform t-test\n",
    "t_stat, p_value = ttest_ind(group1, group2)\n",
    "print('T-statistic:', t_stat)\n",
    "print('P-value:', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Data Visualization\n",
    "Create compelling visualizations to effectively communicate the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Feature Importances\n",
    "Use Random Forest to evaluate feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "# Visualize feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_importances, y=feature_importances.index)\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "This tutorial covered the following key concepts:\n",
    "- Data Preprocessing: Handling missing values, removing outliers, and data transformation.\n",
    "- Exploratory Data Analysis (EDA): Summary statistics and data visualization.\n",
    "- Feature Engineering: Creating new features and handling infinite/NaN values.\n",
    "- Advanced Analysis: Regression, clustering, and hypothesis testing.\n",
    "- Data Visualization: Creating compelling visualizations to communicate findings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
